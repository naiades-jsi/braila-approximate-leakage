{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f4678e",
   "metadata": {},
   "source": [
    "## Testing reading of files\n",
    "Generated by the leakage simulator developed by JSI from DELFT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('./../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "tmp_1 = pd.read_csv(\"simulated_sensor_data_8_cols.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataframe is of length {len(tmp_1.index)}\")\n",
    "tmp_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d89adb",
   "metadata": {},
   "source": [
    "## Determining leak step from duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac83579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate check\n",
    "duplicates = tmp_1[tmp_1[['Sensor1', 'Sensor2', 'Sensor3', 'Sensor4', 'J-Apollo', 'J-RN2',\n",
    "       'J-RN1', 'node_with_leak', 'leak_amount']].duplicated()]\n",
    "display(duplicates)\n",
    "unique_leaks = duplicates[\"leak_amount\"].str.replace(\"LPS\", \"\").unique().astype(float)\n",
    "# display(sorted(list(unique_leaks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leak of 0.002 seems to still be noticable on the foruth decimal of pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35aec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropp the columns containing info about leak and leak amount \n",
    "reduced_df = tmp_1[['Sensor1', 'Sensor2', 'Sensor3', 'Sensor4', 'J-Apollo', 'J-RN2',\n",
    "       'J-RN1', 'node_with_leak']]\n",
    "reduced_df = reduced_df.round(3)\n",
    "display(reduced_df)\n",
    "\n",
    "# drop the rows that aren't unique\n",
    "no_duplicates_df = reduced_df.drop_duplicates()\n",
    "display(no_duplicates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea56f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_leak = pd.merge(no_duplicates_df, tmp_1[\"leak_amount\"], left_index=True, right_index=True)\n",
    "merged_leak[\"leak\"] = merged_leak[\"leak_amount\"].str.replace(\"LPS\", \"\").astype(float)\n",
    "# display(merged_leak)\n",
    "\n",
    "# there 127 unique nodes in the leak network\n",
    "# print(len(merged_leak[\"node_with_leak\"].unique()))\n",
    "\n",
    "nodes_with_leaks_df = merged_leak[[\"leak\", \"node_with_leak\"]].groupby(\"node_with_leak\").agg({\"leak\": list})\n",
    "# display(nodes_with_leaks_df)\n",
    "tmp_1[\"leak\"] = tmp_1[\"leak_amount\"].str.replace(\"LPS\", \"\").astype(float)\n",
    "main_df_grouped = tmp_1[[\"leak\", \"node_with_leak\"]].groupby(\"node_with_leak\")\\\n",
    "                    .agg({\"leak\": list})\n",
    "# display(main_df_grouped)\n",
    "display(len(list(main_df_grouped.loc[\"Node_J-RN1\"].values)[0]))\n",
    "\n",
    "avg = 0\n",
    "for index, row in main_df_grouped.iterrows():\n",
    "    avg += len(row[\"leak\"])\n",
    "    \n",
    "print(avg)\n",
    "avg = avg / 127\n",
    "# there should be 22 601 leakage scenarios generated for every node\n",
    "# in practice there is 22 648 scenarios, of which 47 are duplicated \n",
    "# but here the average of unduplicated values is 1677\n",
    "print(f\"Average number of leaks on each node is {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df533113",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_leak_vals = sorted(list(main_df_grouped.loc[\"Node_J-RN1\"].values)[0])\n",
    "import plotly.express as px\n",
    "\n",
    "#print(len([i for i in range(500, 23101, 1)]))\n",
    "fig = px.scatter(y=all_leak_vals, x=[i for i in range(len(all_leak_vals))])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49f76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b1a7fd1",
   "metadata": {},
   "source": [
    "## Reducing leak step to remove values which are linearly interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a3521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60160efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5eb04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
