{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e840b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('./../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.multicovariate_models.GroupsModelWrapper import GroupsModelWrapper\n",
    "from src.multicovariate_models.DataLoader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be04ae59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor1</th>\n",
       "      <th>Sensor2</th>\n",
       "      <th>Sensor3</th>\n",
       "      <th>Sensor4</th>\n",
       "      <th>J-Apollo</th>\n",
       "      <th>J-RN2</th>\n",
       "      <th>J-RN1</th>\n",
       "      <th>node_with_leak</th>\n",
       "      <th>leak_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0689</td>\n",
       "      <td>14.3960</td>\n",
       "      <td>17.4695</td>\n",
       "      <td>19.1754</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9280</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_275-A</td>\n",
       "      <td>19.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0689</td>\n",
       "      <td>14.3958</td>\n",
       "      <td>17.4695</td>\n",
       "      <td>19.1754</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9280</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_275-A</td>\n",
       "      <td>19.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0688</td>\n",
       "      <td>14.3957</td>\n",
       "      <td>17.4695</td>\n",
       "      <td>19.1754</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9280</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_275-A</td>\n",
       "      <td>19.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0688</td>\n",
       "      <td>14.3956</td>\n",
       "      <td>17.4694</td>\n",
       "      <td>19.1754</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9280</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_275-A</td>\n",
       "      <td>19.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0687</td>\n",
       "      <td>14.3955</td>\n",
       "      <td>17.4694</td>\n",
       "      <td>19.1754</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9280</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_275-A</td>\n",
       "      <td>19.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009579</th>\n",
       "      <td>14.6058</td>\n",
       "      <td>15.6646</td>\n",
       "      <td>17.7761</td>\n",
       "      <td>19.2672</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9421</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_Jonctiune-267</td>\n",
       "      <td>7.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009580</th>\n",
       "      <td>14.6057</td>\n",
       "      <td>15.6646</td>\n",
       "      <td>17.7761</td>\n",
       "      <td>19.2672</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9421</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_Jonctiune-267</td>\n",
       "      <td>7.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009581</th>\n",
       "      <td>14.6057</td>\n",
       "      <td>15.6645</td>\n",
       "      <td>17.7760</td>\n",
       "      <td>19.2672</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9421</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_Jonctiune-267</td>\n",
       "      <td>7.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009582</th>\n",
       "      <td>14.6057</td>\n",
       "      <td>15.6645</td>\n",
       "      <td>17.7760</td>\n",
       "      <td>19.2672</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9421</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_Jonctiune-267</td>\n",
       "      <td>7.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009583</th>\n",
       "      <td>14.6056</td>\n",
       "      <td>15.6644</td>\n",
       "      <td>17.7760</td>\n",
       "      <td>19.2672</td>\n",
       "      <td>15.4271</td>\n",
       "      <td>15.9421</td>\n",
       "      <td>19.8981</td>\n",
       "      <td>Node_Jonctiune-267</td>\n",
       "      <td>7.700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008144 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sensor1  Sensor2  Sensor3  Sensor4  J-Apollo    J-RN2    J-RN1  \\\n",
       "0        14.0689  14.3960  17.4695  19.1754   15.4271  15.9280  19.8981   \n",
       "1        14.0689  14.3958  17.4695  19.1754   15.4271  15.9280  19.8981   \n",
       "2        14.0688  14.3957  17.4695  19.1754   15.4271  15.9280  19.8981   \n",
       "3        14.0688  14.3956  17.4694  19.1754   15.4271  15.9280  19.8981   \n",
       "4        14.0687  14.3955  17.4694  19.1754   15.4271  15.9280  19.8981   \n",
       "...          ...      ...      ...      ...       ...      ...      ...   \n",
       "1009579  14.6058  15.6646  17.7761  19.2672   15.4271  15.9421  19.8981   \n",
       "1009580  14.6057  15.6646  17.7761  19.2672   15.4271  15.9421  19.8981   \n",
       "1009581  14.6057  15.6645  17.7760  19.2672   15.4271  15.9421  19.8981   \n",
       "1009582  14.6057  15.6645  17.7760  19.2672   15.4271  15.9421  19.8981   \n",
       "1009583  14.6056  15.6644  17.7760  19.2672   15.4271  15.9421  19.8981   \n",
       "\n",
       "             node_with_leak  leak_amount  \n",
       "0                Node_275-A       19.500  \n",
       "1                Node_275-A       19.501  \n",
       "2                Node_275-A       19.502  \n",
       "3                Node_275-A       19.503  \n",
       "4                Node_275-A       19.504  \n",
       "...                     ...          ...  \n",
       "1009579  Node_Jonctiune-267        7.696  \n",
       "1009580  Node_Jonctiune-267        7.697  \n",
       "1009581  Node_Jonctiune-267        7.698  \n",
       "1009582  Node_Jonctiune-267        7.699  \n",
       "1009583  Node_Jonctiune-267        7.700  \n",
       "\n",
       "[1008144 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 3.26 s, total: 6.57 s\n",
      "Wall time: 6.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "base_dir = '../../'\n",
    "df = pd.read_csv(os.path.join(base_dir, \"data/dataframes/simulations-step0.01.csv\"))\n",
    "df = df.drop(columns=[\"origin_file\"]).drop_duplicates()\n",
    "\"\"\"main_df = main_df[['Sensor1', 'Sensor2', 'Sensor3', 'Sensor4', 'J-Apollo', 'J-RN2',\n",
    "       'J-RN1', 'node_with_leak']].round(3).drop_duplicates()\"\"\"\n",
    "df['leak_amount'] = df['leak_amount'].str[:-3].astype(float)\n",
    "\n",
    "# drop all the `dpressure` columns\n",
    "dp_col_names = []\n",
    "for col_name in df.columns:\n",
    "    if col_name.endswith('_dpressure'):\n",
    "        dp_col_names.append(col_name)\n",
    "\n",
    "df = df.drop(dp_col_names, axis=1)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c7dc7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (907200, 10), test data shape: (100944, 10)\n",
      "x_train shape: (907200, 7), y_train shape: (907200,)\n",
      "CPU times: user 2.88 s, sys: 708 ms, total: 3.59 s\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# prepare the data for all models\n",
    "data_loader = DataLoader(df)\n",
    "X_train, X_test, y_train, y_test, enc_node_dict = data_loader.get_random_data_split_by_node()\n",
    "#print(X_train, X_test, y_train, y_test, enc_node_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ad77ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "X_train_preproc = data_loader.preprocess_abs_pressure(X_train)\n",
    "X_test_preproc = data_loader.preprocess_abs_pressure(X_test)\n",
    "print(X_train_preproc.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2db24428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 1, CA: 0.5916844983357109\n",
      "n_neighbours: 2, CA: 0.6208095577746078\n",
      "n_neighbours: 3, CA: 0.5891088128071009\n",
      "n_neighbours: 4, CA: 0.6138552068473608\n",
      "n_neighbours: 5, CA: 0.5935766365509589\n",
      "n_neighbours: 6, CA: 0.6196405928039309\n",
      "n_neighbours: 7, CA: 0.5939431764146457\n",
      "n_neighbours: 8, CA: 0.6166686479632271\n",
      "n_neighbours: 9, CA: 0.5974104453954667\n",
      "n_neighbours: 10, CA: 0.6155095894753526\n",
      "n_neighbours: 11, CA: 0.6006597717546363\n",
      "n_neighbours: 12, CA: 0.6163615469963544\n",
      "n_neighbours: 13, CA: 0.5986091298145506\n",
      "n_neighbours: 14, CA: 0.6160544460294817\n",
      "n_neighbours: 15, CA: 0.6023042478998257\n",
      "n_neighbours: 16, CA: 0.6147963227135838\n",
      "n_neighbours: 17, CA: 0.6047412426692027\n",
      "n_neighbours: 18, CA: 0.6166785544460295\n",
      "n_neighbours: 19, CA: 0.605553574258995\n",
      "n_neighbours: 20, CA: 0.6176989221746712\n",
      "n_neighbours: 21, CA: 0.6088821524805833\n",
      "n_neighbours: 22, CA: 0.6178475194167063\n",
      "n_neighbours: 23, CA: 0.6103086860041211\n",
      "n_neighbours: 24, CA: 0.6256934537961643\n",
      "n_neighbours: 25, CA: 0.616579489618006\n"
     ]
    }
   ],
   "source": [
    "for n_neighbours in range(1, 26):\n",
    "    classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbours, p=np.inf)\n",
    "    classifier.fit(X_train_preproc, y_train)\n",
    "\n",
    "    y_hat = classifier.predict(X_test_preproc)\n",
    "\n",
    "    total_diff = np.sum(np.abs(y_test - y_hat) > 0)\n",
    "    ca = 1.0 - total_diff / n_test\n",
    "\n",
    "    print(f'n_neighbours: {n_neighbours}, CA: {ca}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e42c49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours: 24, CA: 0.6256934537961643\n"
     ]
    }
   ],
   "source": [
    "n_neighbours = 24\n",
    "\n",
    "classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbours, p=np.inf)\n",
    "classifier.fit(X_train_preproc, y_train)\n",
    "\n",
    "y_hat = classifier.predict(X_test_preproc)\n",
    "\n",
    "total_diff = np.sum(np.abs(y_test - y_hat) > 0)\n",
    "ca = 1.0 - total_diff / n_test\n",
    "\n",
    "print(f'n_neighbours: {n_neighbours}, CA: {ca}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bef6cda9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lstopar/workspace/JSI/projects/naiades/braila-approximate-leakage/src/analytics/analytics.py:38: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  np.reciprocal(reached_indicator_vec, out=tmp_n)\n"
     ]
    }
   ],
   "source": [
    "# Which nodes can I detect accurately?\n",
    "\n",
    "import json\n",
    "import wntr\n",
    "import src.analytics.analytics as analytics\n",
    "\n",
    "network_fname = '../../data/epanet_networks/Braila_V2022_2_2.inp'\n",
    "water_network_model = wntr.network.WaterNetworkModel(network_fname)\n",
    "network_graph = water_network_model.get_graph()\n",
    "\n",
    "nodeN_to_node_id_map = {nodeN: node_id[5:] for node_id, nodeN in enc_node_dict.items()}\n",
    "\n",
    "# precompute the distances\n",
    "node_dist_map = {}\n",
    "for node_id in network_graph.nodes():\n",
    "    path_len_vec, node_id_vec = analytics.undir_dist_from_set_vec(network_graph, [node_id])\n",
    "    node_dist_map[node_id] = {\n",
    "        'path_len_vec': path_len_vec,\n",
    "        'node_id_vec': node_id_vec\n",
    "    }\n",
    "\n",
    "stats_map = {}\n",
    "for valN, y_val_int64 in enumerate(y_test):\n",
    "    y_val_str = nodeN_to_node_id_map[y_val_int64]\n",
    "    y_hat_val = y_hat[valN]\n",
    "    is_undetectable = 0\n",
    "    \n",
    "    if y_val_str not in stats_map:\n",
    "        stats_map[y_val_str] = {'n_hits': 0, 'n_misses': 0, 'is_undetectable': is_undetectable, 'misclassify_id_map': {}, 'misclassify_dist_map': {}}\n",
    "        \n",
    "    if y_val_int64 == y_hat_val:\n",
    "        stats_map[y_val_str]['n_hits'] += 1\n",
    "    if y_val_int64 != y_hat_val:\n",
    "        stats_map[y_val_str]['n_misses'] += 1\n",
    "        \n",
    "        y_hat_val_str = nodeN_to_node_id_map[y_hat_val]\n",
    "        \n",
    "        if y_hat_val_str not in stats_map[y_val_str]['misclassify_id_map']:\n",
    "            stats_map[y_val_str]['misclassify_id_map'][y_hat_val_str] = 0\n",
    "        stats_map[y_val_str]['misclassify_id_map'][y_hat_val_str] += 1\n",
    "        \n",
    "        # get the distance between y and y_hat\n",
    "        node_dist_props = node_dist_map[y_val_str]\n",
    "        path_len_vec = node_dist_props['path_len_vec']\n",
    "        node_id_vec = node_dist_props['node_id_vec']\n",
    "        \n",
    "        misclassify_dist = -1\n",
    "        for nodeN, node_id in enumerate(node_id_vec):\n",
    "            if node_id == y_hat_val_str:\n",
    "                misclassify_dist = path_len_vec[nodeN]\n",
    "        assert misclassify_dist >= 0\n",
    "        \n",
    "        misclassify_dist = min(10000, misclassify_dist)\n",
    "        \n",
    "        #misclassify_dist = str(path_len_vec[node_id_vec.index(y_hat_val_str)])\n",
    "        \n",
    "        if misclassify_dist not in stats_map[y_val_str]['misclassify_dist_map']:\n",
    "            stats_map[y_val_str]['misclassify_dist_map'][misclassify_dist] = 0\n",
    "        stats_map[y_val_str]['misclassify_dist_map'][misclassify_dist] += 1\n",
    "\n",
    "for node_id, node_stats in stats_map.items():\n",
    "    total_samples = node_stats['n_hits'] + node_stats['n_misses']\n",
    "    node_stats['hit_perc'] = float(node_stats['n_hits']) / total_samples\n",
    "    \n",
    "    misclassify_dist_map = node_stats['misclassify_dist_map']\n",
    "    total_misclassify_count = 0\n",
    "    mean_misclassify_dist = 0.0\n",
    "    max_misclassify_dist = 0.0\n",
    "    for misclassify_dist, misclassify_count in misclassify_dist_map.items():\n",
    "        total_misclassify_count += misclassify_count\n",
    "        mean_misclassify_dist += misclassify_dist*misclassify_count\n",
    "        max_misclassify_dist = max(max_misclassify_dist, misclassify_dist)\n",
    "    mean_misclassify_dist /= total_samples\n",
    "        \n",
    "    node_stats['mean_misclassify_dist'] = mean_misclassify_dist\n",
    "    node_stats['max_misclassify_dist'] = max_misclassify_dist\n",
    "    \n",
    "with open(os.path.join(base_dir, 'model_stats.json'), 'w') as f_out:\n",
    "    json_str = json.dumps(stats_map)\n",
    "    f_out.write(json_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1f376a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "# store the model to disk\n",
    "with open(os.path.join(base_dir, 'data/models/model-knn-v2.pkl'), 'wb') as f_out:\n",
    "    pkl.dump(classifier, f_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
